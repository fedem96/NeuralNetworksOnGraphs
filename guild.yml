########## Planetoid Inductive ##########
- model: Planetoid-i|planetoid-i
  description: Revisiting Semi-Supervised Learning with Graph Embeddings (Yang et al., 2016)
  operations:

    train:
      description: Train Planetoid-I with hyperparameters reported in the paper
      main: Planetoid/train
      sourcecode: 'Planetoid/*.py'
      flags-dest: args
      flags:
        modality: 
          default: "I"

    test:
      description: Test Planetoid; insert the checkpoint to the model (checkpoint-path)
      main: Planetoid/test
      sourcecode: 'Planetoid/*.py'
      flags-dest: args
      flags:
        modality: 
          default: "I"
        checkpoint-path:
          required: True

    evaluate:
      description: ... # TODO:
      sourcecode: 'nothing'
      steps:
        - run: train dataset=[citeseer,cora,pubmed] net-seed=5687 data-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=100000 verbose=0 patience=5000
        - run: train dataset=[citeseer,cora,pubmed] data-seed=5687 net-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=100000 verbose=0 patience=5000
            


########## Planetoid Transductive ##########
- model: Planetoid-t|planetoid-t
  description: Revisiting Semi-Supervised Learning with Graph Embeddings (Yang et al., 2016)
  operations:

    train:
      description: Train Planetoid-T with hyperparameters reported in the paper
      main: Planetoid/train
      sourcecode: 'Planetoid/*.py'
      flags-dest: args
      flags:
        modality: 
          default: "T"
        learning-rate-unsupervised: 
          default: 0.01
        pretrain-batch: 
          default: 2070
        sample-context-rate:
          default: 0.033
        unsupervised-batch: 
          default: 0
        unsupervised-batch-size: 
          default: 200

    test:
      description: Test Planetoid; insert the checkpoint to the model (checkpoint-path)
      main: Planetoid/test
      sourcecode: 'Planetoid/*.py'
      flags-dest: args
      flags:
        modality: 
          default: "T"
        learning-rate-unsupervised: 
          default: 0.01
        pretrain-batch: 
          default: 2070
        sample-context-rate:
          default: 0.033
        unsupervised-batch: 
          default: 0
        unsupervised-batch-size: 
          default: 200
        checkpoint-path:
          required: True

    evaluate:
      description: ... # TODO:
      sourcecode: 'nothing'
      steps:
        - run: train dataset=[citeseer,cora,pubmed] net-seed=5687 data-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=100000 verbose=0 patience=5000
        - run: train dataset=[citeseer,cora,pubmed] data-seed=5687 net-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=100000 verbose=0 patience=5000
   


########## ChebNet ##########
- model: ChebNet|chebnet
  description: Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering (Deferrard et al, 2016)

  operations:

    train:
      description: 
      main: ChebNet/train
      sourcecode: 'ChebNet/*.py'
      flags-dest: args

    train-citeseer:
      description: Train ChebNet on citeseer dataset with hyperparameters reported in GCN paper
      main: ChebNet/train
      sourcecode: 'ChebNet/*.py'
      flags-dest: args
      flags:
        dataset:
          default: citeseer
        num-polynomials:
          default: 4

    train-cora:
      description: Train ChebNet on cora dataset with hyperparameters reported in GCN paper
      main: ChebNet/train
      sourcecode: 'ChebNet/*.py'
      flags-dest: args
      flags:
        dataset:
          default: cora
        num-polynomials:
          default: 3

    train-pubmed:
      description: Train ChebNet on pubmed dataset with hyperparameters reported in GCN paper
      main: ChebNet/train
      sourcecode: 'ChebNet/*.py'
      flags-dest: args
      flags:
        dataset:
          default: pubmed
        num-polynomials:
          default: 4

    test: # TODO: finish
      description: 
      main: ChebNet/test
      sourcecode: 'ChebNet/*.py'
      flags-dest: args

    evaluate:
      description: ... # TODO:
      sourcecode: 'nothing'
      steps:
        - run: train-citeseer net-seed=5687 data-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=400 patience=20 verbose=0
        - run: train-cora     net-seed=5687 data-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=400 patience=20 verbose=0
        - run: train-pubmed   net-seed=5687 data-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=400 patience=20 verbose=0
        - run: train-citeseer data-seed=5687 net-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=400 patience=20 verbose=0
        - run: train-cora     data-seed=5687 net-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=400 patience=20 verbose=0
        - run: train-pubmed   data-seed=5687 net-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=400 patience=20 verbose=0
                                                                                                                                                                                         # in GCN paper: epochs=200 patience=10


########## GCN ##########
- model: GCN|gcn
  description: Semi-Supervised Classification with Graph Convolutional Netowrks (Kipf and welling, 2017)

  operations:

    train:
      description: 
      main: GCN/train
      sourcecode: 'GCN/*.py'
      flags-dest: args

    test: # TODO: finish
      description: 
      main: GCN/test
      sourcecode: 'GCN/*.py'
      flags-dest: args

    evaluate:
      description: ... # TODO:
      sourcecode: 'nothing'
      steps:
        - run: train dataset=[citeseer,cora,pubmed] net-seed=5687 data-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=400 patience=20 verbose=0
        - run: train dataset=[citeseer,cora,pubmed] data-seed=5687 net-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=400 patience=20 verbose=0
                                                                                                                                                                                                               # in GCN paper: epochs=200 patience=10



########## GAT ##########
- model: GAT|gat
  description: Graph Attention Networks ( Velickovic et al., 2018)

  operations:

    train:
      description: 
      main: GAT/train
      sourcecode: 'GAT/*.py'
      flags-dest: args

    train-citeseer:
      description: Train GAT on citeseer dataset with hyperparameters reported in the paper
      main: GAT/train
      sourcecode: 'GAT/*.py'
      flags-dest: args
      flags:
        dataset:
          default: citeseer

    train-cora:
      description: Train GAT on cora dataset with hyperparameters reported in the paper
      main: GAT/train
      sourcecode: 'GAT/*.py'
      flags-dest: args
      flags:
        dataset:
          default: cora

    train-pubmed:
      description: Train GAT on pubmed dataset with hyperparameters reported in the paper
      main: GAT/train
      sourcecode: 'GAT/*.py'
      flags-dest: args
      flags:
        dataset:
          default: pubmed
        nheads:
          default: 8,8
        learning-rate:
          default: 0.01
        l2-weight:
          default: 0.001        
    
    test:
      description: 
      main: GAT/test
      sourcecode: 'GAT/*.py'
      flags-dest: args
      flags:
        checkpoint-path:
          required: True

    evaluate:
      description: ... # TODO:
      sourcecode: 'nothing'
      steps:
        - run: train-citeseer net-seed=5687 data-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=1000 verbose=0
        - run: train-cora     net-seed=5687 data-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=1000 verbose=0
        - run: train-pubmed   net-seed=5687 data-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=1000 verbose=0
        - run: train-citeseer data-seed=5687 net-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=1000 verbose=0
        - run: train-cora     data-seed=5687 net-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=1000 verbose=0
        - run: train-pubmed   data-seed=5687 net-seed=[9516,1353,551,4975,9399,6608,5688,8964,872,6473,3747,7920,8089,3603,8960,516,2616,2674,7135,728,9493,5414,828,1356,8175,2107,9099,7075,4848,5154] epochs=1000 verbose=0
